{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f1159df9",
   "metadata": {},
   "source": [
    "# Group Assignment #4"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0389da92",
   "metadata": {},
   "source": [
    "# Use the credit_default_model_data.csv dataset, that’s available both on Canvas and on the class GitHub repository, to perform cluster analysis using the k-means clustering method."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "579255d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# data processing\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# modeling\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.metrics import silhouette_score\n",
    "\n",
    "# plotting\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "cdm = pd.read_csv(r\"C:\\Users\\alvin\\Python HW\\data\\credit_default_model_data.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3663092d",
   "metadata": {},
   "source": [
    "# Please discard the following two columns: group and default payment next month"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0388ec99",
   "metadata": {},
   "source": [
    "# Consider all permutations listed below for the number of clusters and the number of principal components (to be used for clustering) and find out which combination generates the best clustering solution. \n",
    "Use Silhouette scores to assess clustering solutions. For this step, use a random sample of 10,000 records from the\n",
    "dataset.\n",
    "• Number of clusters: 4, 5, 6, 7, 8, 9\n",
    "• Number of principal components: 10, 15, 20, 25, 30\n",
    "\n",
    "Select the best number of clusters and principal components based on this analysis. (Pick the set of values that generate the highest Silhouette score.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f55b8ce3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# read in data and drop unnecessary columns\n",
    "cdm = pd.read_csv(r\"C:\\Users\\alvin\\Python HW\\data\\credit_default_model_data.csv\")\n",
    "cdm.drop(['group', 'default payment next month'], axis=1, inplace=True)\n",
    "\n",
    "# set up list of cluster and PCA component values to try\n",
    "num_clusters = [4, 5, 6, 7, 8, 9]\n",
    "num_components = [10, 15, 20, 25, 30]\n",
    "\n",
    "# take a random sample of 10,000 records\n",
    "cdm_sample = cdm.sample(n=10000, random_state=42)\n",
    "\n",
    "# iterate over all permutations of cluster and PCA component values\n",
    "best_score = -1\n",
    "best_params = None\n",
    "for n_clusters in num_clusters:\n",
    "    for n_components in num_components:\n",
    "        \n",
    "        # standardize the features\n",
    "        scaler = StandardScaler()\n",
    "        X_scaled = scaler.fit_transform(cdm_sample)\n",
    "        \n",
    "        # perform PCA\n",
    "        pca = PCA(n_components=n_components)\n",
    "        X_pca = pca.fit_transform(X_scaled)\n",
    "        \n",
    "        # perform KMeans clustering\n",
    "        kmeans = KMeans(n_clusters=n_clusters, random_state=42)\n",
    "        cluster_labels = kmeans.fit_predict(X_pca)\n",
    "        \n",
    "        # calculate silhouette score\n",
    "        score = silhouette_score(X_pca, cluster_labels)\n",
    "        \n",
    "        # check if this is the best score so far\n",
    "        if score > best_score:\n",
    "            best_score = score\n",
    "            best_params = (n_clusters, n_components)\n",
    "            \n",
    "# print the best score and parameters\n",
    "print(\"Best Silhouette Score:\", best_score)\n",
    "print(\"Number of Clusters:\", best_params[0])\n",
    "print(\"Number of PCA Components:\", best_params[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b134fe51",
   "metadata": {},
   "source": [
    "# Now take the entire dataset and build the final clustering model using those two values. Store the assigned cluster (number) for each record in a new column in the dataframe. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ebcaf12f",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Scale the features\n",
    "scaler = StandardScaler()\n",
    "\n",
    "# Perform PCA with 10 principal components\n",
    "pca = PCA(n_components=10)\n",
    "X_pca = pca.fit_transform(X_scaled)\n",
    "\n",
    "# Fit the clustering model with the best number of clusters and principal components\n",
    "kmeans = KMeans(n_clusters=7 andom_state=42)\n",
    "kmeans.fit(X_scaled[:, :7])\n",
    "\n",
    "# Fit the k-means algorithm on the entire dataset\n",
    "kmeans.fit(cdm[['PAY_AMT1', 'PAY_AMT2']])\n",
    "\n",
    "# Assign cluster number to each record and add a new column to the dataframe\n",
    "cdm['Cluster'] = kmeans.labels_"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "224c93d4",
   "metadata": {},
   "source": [
    "# Create a cluster profile report that shows the average (mean) value of each numeric feature by cluster"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8917bcd",
   "metadata": {},
   "outputs": [],
   "source": [
    "cluster_profile = cdm.groupby('Cluster').mean().reset_index()\n",
    "print(cluster_profile)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
